{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18ae4742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import smtplib\n",
    "import time\n",
    "import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50988f6",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "405878f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-f3bdf3cc6110>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-f3bdf3cc6110>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    headers = {\"INSERTUSERAGENTHERE\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\u001b[0m\n\u001b[1;37m                                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Connect to Amazon and get url of product to watch\n",
    "# user agent from here: https://httpbin.org/get\n",
    "\n",
    "url = 'https://www.amazon.co.uk/gp/product/B077RV492Y/ref=ox_sc_saved_title_2?smid=A3G7SO46F6U6Y1&th=1'\n",
    "\n",
    "\n",
    "# user agent \n",
    "headers = {\"INSERTUSERAGENTHERE\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "\n",
    "# request to url \n",
    "page = requests.get(url, headers=headers)\n",
    "\n",
    "\n",
    "#pull content from page\n",
    "soup = BeautifulSoup(page.content, \"html.parser\" )\n",
    "\n",
    "\n",
    "title = soup.find(id='productTitle').get_text() #find title from id element\n",
    "price = soup.find(\"span\",{\"class\":\"a-offscreen\"}).get_text() #find price from class element\n",
    "rating = soup.find(id='acrPopover').get_text()\n",
    "\n",
    "print(title)\n",
    "print(price)\n",
    "print(rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b450f6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.99\n",
      "KROSER School Laptop Backpack Large Travel Computer Backpack for 17.3 Inch Laptop with USB Charging Port Water-Repellent Casual Daypack for Business/College/Women/Men-Charcoal Black\n",
      "4.7 out of 5 stars\n"
     ]
    }
   ],
   "source": [
    "price = price[1:] #strip first char 0\n",
    "title = title.strip() #strip space if any \n",
    "rating = rating.strip()\n",
    "\n",
    "print(price)\n",
    "print(title)\n",
    "print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "674a5e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" #comment out after creating initial csv\n",
    "\n",
    "#prepare data to insert\n",
    "header=['Title','Price','Rating','Date'] #set header for csv\n",
    "data = [title,price,rating,datetime.date.today()] #insert title,price & todays date \n",
    "\n",
    "#insert title,price,rating and date into csv\n",
    "with open('Product_info.csv', 'w', newline = '',  encoding='UTF8') as a: #newline to rid of extra blank row\n",
    "    csv.writer(a).writerow(header) #insert header\n",
    "    csv.writer(a).writerow(data) #inser tdata\n",
    "    \n",
    "  \"\"\"  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ef27a1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above, change to a+ to append data, remove writer=header as already created\n",
    "\n",
    "#append data, inserted above \n",
    "with open('Product_info.csv', 'a+', newline = '',  encoding='UTF8') as a: #newline to rid of extra blank row\n",
    "    csv.writer(a).writerow(data) #append tdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020a856d",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88de3ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert all above into function to automate\n",
    "# user agent from here: https://httpbin.org/get\n",
    "\n",
    "\n",
    "def check_price():\n",
    "    url = 'https://www.amazon.co.uk/gp/product/B077RV492Y/ref=ox_sc_saved_title_2?smid=A3G7SO46F6U6Y1&th=1'\n",
    "\n",
    "\n",
    "    # user agent \n",
    "    headers = {\"INSERTUSERAGENTHERE\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "\n",
    "    # request to url \n",
    "    page = requests.get(url, headers=headers)\n",
    "\n",
    "\n",
    "    #pull content from page\n",
    "    soup1 = BeautifulSoup(page.content, \"html.parser\" )\n",
    "\n",
    "    soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")\n",
    "\n",
    "    title = soup2.find(id='productTitle').get_text() #find title from id element\n",
    "\n",
    "    price = soup2.find(\"span\",{\"class\":\"a-offscreen\"}).get_text() #find price from class element\n",
    "\n",
    "    rating = soup2.find(id='acrPopover').get_text()\n",
    "    \n",
    "    price = price.strip()[1:] #strip space + first char 0\n",
    "    title = title.strip() #strip space if any \n",
    "    rating = rating.strip()\n",
    "    \n",
    "    header=['Title','Price','Rating','Date'] #set header for csv\n",
    "    data = [title,price,rating,datetime.date.today()] #insert title,price & todays date \n",
    "    \n",
    "    with open('Product_info.csv', 'a+', newline = '',  encoding='UTF8') as a: #newline to rid of extra blank row\n",
    "        csv.writer(a).writerow(data) #append tdata\n",
    "        \n",
    "#    if(price > 25.99): import libraries if required\n",
    "#        upload_dropbox()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35c65a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_price()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8399d052",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Can run the below to check price and append new data every 48h\n",
    "\n",
    "while(True):\n",
    "    check_price()\n",
    "    time.sleep(172800) \n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feab65a0",
   "metadata": {},
   "source": [
    "#### upload_dropbox function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "28e11ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "import dropbox\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b97c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Uploads document to dropbox \n",
    "def upload_dropbox():\n",
    "    df = pd.read_csv(r'FILELOCATION') #read into df\n",
    "    \n",
    "    DBX = dropbox.Dropbox('DROPBOXTOKEN') #connect to dropbox via DBX api\n",
    "    DBX.files_upload(df.to_csv(index=False).encode(), \"/Product_\", mode=dropbox.files.WriteMode.overwrite) #upload to dropbox\n",
    "    \n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
